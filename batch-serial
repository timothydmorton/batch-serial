#!/usr/bin/env python

"""
Launches batch job running every line of input file.

Uses slurm job array by default, but could be reconfigured
to another batch scheduler if desired.

By default assumes 20 cores per node.
"""
from __future__ import print_function, division

import os,re,sys,os.path,shutil,glob
import argparse
import numpy as np
import subprocess

if __name__=='__main__':
    parser = argparse.ArgumentParser(description='Fire up a batch serial job')

    parser.add_argument('file', type=str)
    parser.add_argument('command', type=str, nargs='?', default=None, 
                        help='Optional argument, to specify command to ' +
                        'apply to each line of file')
    parser.add_argument('-n', '--nsplit', type=int, default=None,
                        help='Total number of jobs to split into.  ' +
                        'Will default to length of file.')
    parser.add_argument('--ntasks_per_node', type=int, default=20,
                        help='number of cores to use per node.')
    
    parser.add_argument('-t', '--time', type=float, default=5,
                        help='approximate time that one line will take, '+
                        'in minutes')
    
    parser.add_argument('--test', action='store_true',
                        help='If set, then just write batch script, not run')

    parser.add_argument('--qsched', type=str, default='slurm')
    parser.add_argument('--condor', action='store_true')

    parser.add_argument('args', nargs=argparse.REMAINDER)

    args = parser.parse_args()
    
    if args.condor:
        args.qsched = 'condor'

    listfile = os.path.abspath(args.file)

    num_lines = sum(1 for line in open(listfile))
    nsplit = num_lines if args.nsplit is None else args.nsplit

    n_nodes = nsplit // (args.ntasks_per_node)
    if nsplit % args.ntasks_per_node != 0:
        n_nodes += 1
    
    if nsplit < args.ntasks_per_node:
        ntasks_per_node = nsplit
    else:
        ntasks_per_node = args.ntasks_per_node

    num_per_job = num_lines // nsplit
    if num_lines % nsplit != 0:
        num_per_job += 1
    tot_minutes = args.time*num_per_job
    time_string = '{:02.0f}:{:02.0f}:00'.format(tot_minutes//60, tot_minutes % 60)

    scriptfile = '{}.{}'.format(listfile, args.qsched)
    fout = open(scriptfile, 'w')

    if args.qsched == 'slurm':
            
        fout.write('#!/bin/bash\n')
        fout.write('#SBATCH -J starfit-{}\n'.format(args.file))
        fout.write('#SBATCH -N {}\n'.format(n_nodes))
        fout.write('#SBATCH --ntasks-per-node={}\n'.format(ntasks_per_node))
        fout.write('#SBATCH -t {}\n'.format(time_string))
        fout.write('\n')
        fout.write('for ((i=0; i<=$(expr $SLURM_NPROCS-1); i++)) do\n' +
                   ' awk "NR % ${{SLURM_NPROCS}} == $i" {} | '.format(listfile))
        if args.command is not None:
            fout.write('xargs {} '.format(args.command))
            for arg in args.args:
                fout.write('{} '.format(arg))
            fout.write(' &\n')
        else:
            fout.write('bash &\n')
        fout.write('done\n' +
                   'wait\n')

    elif args.qsched == 'condor':
        if args.command is None:
            raise ValueError('Must have command if launching condor script')

        fout.write('universe = vanilla\n')
        fout.write('executable = {}\n'.format(args.command))
        


    fout.close()

    if not args.test:
        #execute slurm batch job
        subprocess.call('sbatch {}'.format(scriptfile), shell=True)

